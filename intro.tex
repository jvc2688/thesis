\documentclass[12pt, preprint]{aastex}

\usepackage{subfigure}
\usepackage{color}
\usepackage{hyperref}
\usepackage{url}
\usepackage{natbib}

\newcommand{\project}[1]{\textsl{#1}} 
\newcommand{\todo}[1]{\textbf{#1}}
\newcommand{\kepler}{\project{Kepler}}
\newcommand{\pdc}{\project{PDC}}
\newcommand{\galex}{\project{GALEX}}
\newcommand{\ktwo}{\project{K2}}
\newcommand{\sdss}{\project{SDSS}}

\graphicspath{{figures/}}

\bibliographystyle{apj}
\definecolor{linkcolor}{rgb}{0,0,0.5}
\hypersetup{colorlinks=true,linkcolor=linkcolor,citecolor=linkcolor,filecolor=linkcolor,urlcolor=linkcolor}

%temp
\input{definitions}


\begin{document}

\section{Introduction}
Just as all physics experiments, measuring the underlying physical quantity of interest is crucial for astronomy research.

Traditionally, calibration 
Traditional calibration
calibration data and science data is not observed simultaneously
Because of these 

However self-calibration that utilizes the science data

\subsection{Photometric calibration in wide-field imaging surveys}
SDSS self-calibration 

\subsection{Data-driven model}
The model can be a physical model (of the spacecraft PSF, pointing, temperature, and so on) or it can be a flexible, effective model that has no direct interpretation in terms of physical spacecraft parameters.
In a physical model, this mapping function is usually decomposed into different parts including telescope pointing, PSF, flat-field, distortion map and so on.
 and it's easy to input the prior information 
However if the prior knowledge is wrong or incomplete, then a physical model 

Instead of 
An successful example of this kind of flexible, effective models is the \kepler\ Presearch Data Conditioning (\pdc, \citealt{pdc1}, \citealt{pdc2}, \citealt{pdc3}). 
The \pdc\ builds on the idea that systematic errors have a temporal structure that can be extracted from ancillary quantities.
\pdc\ ``co-trends'' or calibrates the \kepler\ light curves by removing those parts that are explained by the basis light curves generated from a principal components analysis (PCA) of filtered light curves.
That is, it exploits statistical dependences between different time series, regularizing the fit (and avoiding over-fitting) by filtering and restricting the dimensionality (through PCA).

%In \chap{cpm}, we will discuss  

If done well, we would expect a physical model to do a better job, because it embodies more prior information, but it requires research and intuition about dominant effects. 
If this research and intuition is wrong or incomplete, a physical model may actually perform worse. The model we propose here is in the non-physical, effective category. The Kepler community is familiar with these kinds of models; to our knowledge, all successful light curve “de-trending” methods are flexible, effective models.

2 Pdc cotrending, but could not totally separate the intrinsic stellar variability and  systematics, didn’t use the pixel level info

crowded field photomerty
3 traditional difference imaging is good for crowd field because doing differentiate photometry. However the its performance depends on the the psf

\subsection{Crowded fields photometry}
One of the biggest challenge in astronomical observation is doing photometry in a crowded fields.
Crowded fields photometry is hard because stars in the field are not be isolated.
Therefore aperture photometry is not applicable in this situation.

A conventional approach for crowded fields photometry is to reduce images into catalogs of point sources and build a comprehensive model for the point-spread function (PSF),  the sky background, and so on (\citealt{psf1}, \citealt{psf2}).
The challenges in this kind of approach include but not limited to imperfect deblending, sources detection and PSF fitting.
The model complexity also scales with the number of the sources in the field (\citealt{crowd1}, \citealt{crowd2}, \citealt{crowd3}).

However in many situations, it is only the variable sources and the differential photometry between image frames are interested.
Therefore the complexities of photometry in a crowded field can be greatly reduced, if the constant sources in the field can be properly removed.

Difference imaging or image subtraction (\citealt{imagesub1}, \citealt{alard}, \citealt{varyingkernel}) is a method developed for detecting and doing differential photometry for variable objects and in crowded fields, in which the difference is measured between two images that are both positionally and photometrically matched.
The common workflow for difference imaging is:
\begin{enumerate}
\item
Create a reference image by either stacking image frames or selecting the frame with the best seeing.
\item
Astrometrically register each frame to the reference frame.
\item
Match the seeing between each image and the reference frame by fitting a convolution kernel that accounts for the differences between the point spread functions(PSFs).
\item
Match the mean throughput or photometric calibration of the two frames and subtract to get a difference image.
\end{enumerate}

The difference between 
Difference imaging has been successfully applied for the detection of variable sources in microlensing \citep{macho, ogle} and supernova \citep{sdss} surveys.

However all these difference imaging method only utilize the spatial constrain between nearby pixels of two image frames.
There are situations that data are taken very differently like \ktwo(\citep{k2}), in which thousands of images of the same field are taken in different time stamps.
In \chap{cdi}, we proposed a totally different method that do not make a reference image and make a model of how pixels predict one another, using the full time history of the data.

\subsection{Outline and contributions}
\chap{cpm} has been refereed and published in the astronomical literature.
\Chap{cdi} has been submitted to \emph{The Astrophysical Journal}.
\Chap{gs} is in preparation for submission.
All of these \chapname s were co-authored with collaborators but the majority of the work and writing in each \chapname\ is mine.
Here, I describe my specific contributions to each \chapname:
\begin{enumerate}

{\item For \chap{gs}  I developed the project idea in collaboration with David Hogg, David Schiminovich and Steven Mohammed.
I implemented the project with contributions from Steven Mohammed.
The project utilized software written by Chase Million.
I wrote the paper with additions by David Hogg.}

{\item The fundamental ideas underlying \chap{cpm} were developed through discussions with David Hogg, Daniel Foreman-Mackey and Bernhard Sch\"olkopf.
I then implemented the project and wrote the paper with Sections contributed by David Hogg and additions by Daniel Foreman-Mackey and Bernhard Sch\"olkopf.}

{\item For \chap{cdi} I developed the idea for the project in collaboration with David Hogg, Daniel Foreman-Mackey, and Bernhard Sch\"olkopf.
I implemented the project and wrote the paper with additions by David Hogg, Daniel Foreman-Mackey and Bernhard Scho\"lkopf.
}
\end{enumerate}

\subsection{Acknowledgement of data and computational resources}

\clearpage
\bibliography{intro}
%\input{cpm.bbl}
\clearpage

\end{document}